{"cells":[{"cell_type":"markdown","metadata":{"id":"FyRdDYkqAKN4"},"source":["## Before you start\n","\n","Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1697060054769,"user":{"displayName":"","userId":""},"user_tz":240},"id":"Y8cDtxLIBHgQ","outputId":"fbf099fc-84e1-4303-f7d9-e7e88da7cc07"},"outputs":[{"name":"stdout","output_type":"stream","text":["zsh:1: command not found: nvidia-smi\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1697060143495,"user":{"displayName":"Card Playing Robot","userId":"14349880449814049551"},"user_tz":240},"id":"CjpPg4mGKc1v","outputId":"57d2c4ca-03d7-4fa4-9041-07e1bcf299d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["/Users/chavezmunoz.a/Documents/Dev/CardPlayingRobot/Card-Playing-Robot\n"]}],"source":["import os\n","HOME = os.getcwd()\n","print(HOME)"]},{"cell_type":"markdown","metadata":{"id":"3C3EO_2zNChu"},"source":["## Install YOLOv8\n","\n","⚠️ YOLOv8 is still under heavy development. Breaking changes are being introduced almost weekly. We strive to make our YOLOv8 notebooks work with the latest version of the library. Last tests took place on **27.01.2023** with version **YOLOv8.0.20**.\n","\n","If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.\n","\n","YOLOv8 can be installed in two ways - from the source and via pip. This is because it is the first iteration of YOLO to have an official package."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13967,"status":"ok","timestamp":1697060173596,"user":{"displayName":"Card Playing Robot","userId":"14349880449814049551"},"user_tz":240},"id":"tdSMcABDNKW-","outputId":"8a008600-a406-4eb4-bd3e-f689ecc6c567"},"outputs":[{"name":"stderr","output_type":"stream","text":["Ultralytics YOLOv8.0.20 🚀 Python-3.9.12 torch-2.1.0 CPU\n","Setup complete ✅ (8 CPUs, 16.0 GB RAM, 198.9/228.3 GB disk)\n"]}],"source":["# Pip install method (recommended)\n","\n","!pip install ultralytics==8.0.20\n","\n","from IPython import display\n","display.clear_output()\n","\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":388,"status":"ok","timestamp":1697060182032,"user":{"displayName":"Card Playing Robot","userId":"14349880449814049551"},"user_tz":240},"id":"VOEYrlBoP9-E"},"outputs":[],"source":["from ultralytics import YOLO\n","\n","from IPython.display import display, Image"]},{"cell_type":"markdown","metadata":{"id":"HnnZSm5OQfPQ"},"source":["## CLI Basics"]},{"cell_type":"markdown","metadata":{"id":"K33S7zlkQku0"},"source":["If you want to train, validate or run inference on models and don't need to make any modifications to the code, using YOLO command line interface is the easiest way to get started. Read more about CLI in [Ultralytics YOLO Docs](https://docs.ultralytics.com/usage/cli/).\n","\n","```\n","yolo task=detect    mode=train    model=yolov8n.yaml      args...\n","          classify       predict        yolov8n-cls.yaml  args...\n","          segment        val            yolov8n-seg.yaml  args...\n","                         export         yolov8n.pt        format=onnx  args...\n","```"]},{"cell_type":"markdown","metadata":{"id":"s5RGYA6sPgEd"},"source":["## Inference with Pre-trained COCO Model"]},{"cell_type":"markdown","metadata":{"id":"fT1qD4toTTw0"},"source":["### 💻 CLI"]},{"cell_type":"markdown","metadata":{"id":"ZaE1kLS8R4CV"},"source":["`yolo mode=predict` runs YOLOv8 inference on a variety of sources, downloading models automatically from the latest YOLOv8 release, and saving results to `runs/predict`."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14303,"status":"ok","timestamp":1697060223801,"user":{"displayName":"Card Playing Robot","userId":"14349880449814049551"},"user_tz":240},"id":"FDbMt_M6PiXb","outputId":"0d8e7af0-fce9-4051-e3d6-1ba30d310987"},"outputs":[{"name":"stdout","output_type":"stream","text":["/Users/chavezmunoz.a/Documents/Dev/CardPlayingRobot/Card-Playing-Robot\n","Ultralytics YOLOv8.0.20 🚀 Python-3.9.12 torch-2.1.0 CPU\n","[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n","YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n","Found https://media.roboflow.com/notebooks/examples/dog.jpeg locally at dog.jpeg\n","image 1/1 /Users/chavezmunoz.a/Documents/Dev/CardPlayingRobot/Card-Playing-Robot/dog.jpeg: 640x384 1 person, 1 car, 1 dog, 218.7ms\n","Speed: 1.1ms pre-process, 218.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n"]}],"source":["%cd {HOME}\n","!yolo task=detect mode=predict model=yolov8n.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg' save=True"]},{"cell_type":"markdown","metadata":{"id":"AFMBYQtMVL-B"},"source":["### 🐍 Python SDK\n","\n","The simplest way of simply using YOLOv8 directly in a Python environment."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15025,"status":"ok","timestamp":1697060238821,"user":{"displayName":"Card Playing Robot","userId":"14349880449814049551"},"user_tz":240},"id":"Rx9NWF-sVN6Y","outputId":"69a7e0c7-521f-4d1f-a8a6-1adf13181030"},"outputs":[{"name":"stderr","output_type":"stream","text":["Ultralytics YOLOv8.0.20 🚀 Python-3.9.12 torch-2.1.0 CPU\n","YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n","Found https://media.roboflow.com/notebooks/examples/dog.jpeg locally at dog.jpeg\n"]}],"source":["model = YOLO(f'{HOME}/yolov8n.pt')\n","results = model.predict(source='https://media.roboflow.com/notebooks/examples/dog.jpeg', conf=0.25)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":123824,"status":"ok","timestamp":1697060420054,"user":{"displayName":"Card Playing Robot","userId":"14349880449814049551"},"user_tz":240},"id":"BSd93ZJzZZKt","outputId":"e577e0e3-cbb8-4eee-a25a-1724e7e657d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: /Users/chavezmunoz.a/Documents/Dev/CardPlayingRobot/Card-Playing-Robot/datasets: File exists\n","/Users/chavezmunoz.a/Documents/Dev/CardPlayingRobot/Card-Playing-Robot/datasets\n","Requirement already satisfied: roboflow in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (1.1.7)\n","Requirement already satisfied: python-dotenv in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (1.0.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (4.66.1)\n","Requirement already satisfied: matplotlib in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (3.8.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (1.4.3)\n","Requirement already satisfied: opencv-python-headless==4.8.0.74 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (4.8.0.74)\n","Requirement already satisfied: supervision in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (0.14.0)\n","Requirement already satisfied: cycler==0.10.0 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (0.10.0)\n","Requirement already satisfied: requests in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: numpy>=1.18.5 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (1.22.4)\n","Requirement already satisfied: PyYAML>=5.3.1 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (6.0.1)\n","Requirement already satisfied: requests-toolbelt in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (1.0.0)\n","Requirement already satisfied: python-dateutil in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (2.8.2)\n","Requirement already satisfied: idna==2.10 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (2.10)\n","Requirement already satisfied: urllib3>=1.26.6 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (2.0.6)\n","Requirement already satisfied: pyparsing==2.4.7 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (2.4.7)\n","Requirement already satisfied: chardet==4.0.0 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (4.0.0)\n","Requirement already satisfied: six in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (1.16.0)\n","Requirement already satisfied: certifi==2022.12.7 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (2022.12.7)\n","Requirement already satisfied: Pillow>=7.1.2 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from roboflow) (9.5.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from matplotlib->roboflow) (1.1.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from matplotlib->roboflow) (4.33.3)\n","Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from matplotlib->roboflow) (21.3)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from matplotlib->roboflow) (6.1.0)\n","Requirement already satisfied: zipp>=3.1.0 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->roboflow) (3.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from requests->roboflow) (3.3.0)\n","Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /opt/anaconda3/envs/ComputerVision/lib/python3.9/site-packages (from supervision->roboflow) (1.11.3)\n","loading Roboflow workspace...\n","loading Roboflow project...\n","Dependency ultralytics==8.0.134 is required but found version=8.0.20, to fix: `pip install ultralytics==8.0.134`\n"]},{"name":"stderr","output_type":"stream","text":["Downloading Dataset Version Zip in Playing-Cards-4 to yolov8:: 100%|██████████| 2119661/2119661 [03:13<00:00, 10980.95it/s]"]},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["\n","Extracting Dataset Version Zip to Playing-Cards-4 in yolov8:: 100%|██████████| 48478/48478 [00:13<00:00, 3621.29it/s]\n"]}],"source":["!mkdir {HOME}/datasets\n","%cd {HOME}/datasets\n","\n","!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"x12y8Ie3WcmQQmcLoO9m\")\n","project = rf.workspace(\"augmented-startups\").project(\"playing-cards-ow27d\")\n","dataset = project.version(4).download(\"yolov8\")\n"]},{"cell_type":"markdown","metadata":{"id":"YUjFBKKqXa-u"},"source":["## Custom Training"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D2YkphuiaE7_","outputId":"b3428adb-63a4-4621-cbe0-cb9756ba75b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["/Users/chavezmunoz.a/Documents/Dev/CardPlayingRobot/Card-Playing-Robot\n","Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt to yolov8s.pt...\n","100%|██████████████████████████████████████| 21.5M/21.5M [00:02<00:00, 10.7MB/s]\n","\n","Ultralytics YOLOv8.0.20 🚀 Python-3.9.12 torch-2.1.0 CPU\n","\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.yaml, data=/Users/chavezmunoz.a/Documents/Dev/CardPlayingRobot/Card-Playing-Robot/datasets/Playing-Cards-4/data.yaml, epochs=25, patience=50, batch=16, imgsz=800, save=True, cache=False, device=, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, save_dir=runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to /Users/chavezmunoz.a/Library/Application Support/Ultralytics/Arial.ttf...\n","100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 13.1MB/s]\n","Overriding model.yaml nc=80 with nc=52\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.Conv                  [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.C2f                   [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.C2f                   [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.C2f                   [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.C2f                   [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.C2f                   [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2136172  ultralytics.nn.modules.Detect                [52, [128, 256, 512]]         \n","[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n","Model summary: 225 layers, 11155724 parameters, 11155708 gradients, 28.8 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/chavezmunoz.a/Documents/Dev/CardPlayingRobot/Card-Playing\u001b[0m\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/chavezmunoz.a/Documents/Dev/CardPlayingRobot/Card-Playing-Robot/datasets/Playing-Cards-4/train/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/chavezmunoz.a/Documents/Dev/CardPlayingRobot/Card-Playing-R\u001b[0m\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/chavezmunoz.a/Documents/Dev/CardPlayingRobot/Card-Playing-Robot/datasets/Playing-Cards-4/valid/labels.cache\n","Image sizes 800 train, 800 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns/detect/train\u001b[0m\n","Starting training for 25 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/25         0G      2.644      10.91      1.937        108        800:  "]}],"source":["%cd {HOME}\n","\n","!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=25 imgsz=800 plots=True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MScstfHhArr","outputId":"210f2b1e-aea6-464b-d69e-319c473338a4"},"outputs":[],"source":["!ls {HOME}/runs/detect/train/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":484},"id":"_J35i8Ofhjxa","outputId":"3584e96f-5a55-4391-c51f-3acf53f80cd9"},"outputs":[],"source":["%cd {HOME}\n","Image(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=600)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":334},"id":"A-urTWUkhRmn","outputId":"836e9053-7035-48ba-ef10-9f7155a329de"},"outputs":[],"source":["%cd {HOME}\n","Image(filename=f'{HOME}/runs/detect/train/results.png', width=600)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"id":"HI4nADCCj3F5","outputId":"ad7f1e75-222c-4097-ee6a-edcff68ff723"},"outputs":[],"source":["%cd {HOME}\n","Image(filename=f'{HOME}/runs/detect/train/val_batch0_pred.jpg', width=600)"]},{"cell_type":"markdown","metadata":{"id":"6ODk1VTlevxn"},"source":["## Validate Custom Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YpyuwrNlXc1P","outputId":"f0bb32ee-5da7-4249-f6e8-bb19ef860b4d"},"outputs":[],"source":["%cd {HOME}\n","\n","!yolo task=detect mode=val model={HOME}/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml"]},{"cell_type":"markdown","metadata":{"id":"i4eASbcWkQBq"},"source":["## Inference with Custom Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wjc1ctZykYuf","outputId":"95967de2-7d16-414a-dfc5-7c8eb38065e6"},"outputs":[],"source":["%cd {HOME}\n","!yolo task=detect mode=predict model={HOME}/runs/detect/train/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True"]},{"cell_type":"markdown","metadata":{"id":"mEYIo95n-I0S"},"source":["**NOTE:** Let's take a look at few results."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"jbVjEtPAkz3j","outputId":"94a5d40d-62e8-4347-bd4b-183aae9e002a"},"outputs":[],"source":["import glob\n","from IPython.display import Image, display\n","\n","for image_path in glob.glob(f'{HOME}/runs/detect/predict3/*.jpg')[:3]:\n","      display(Image(filename=image_path, width=600))\n","      print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"j0tsVilOCPyq"},"source":["## Deploy model on Roboflow\n","\n","Once you have finished training your YOLOv8 model, you’ll have a set of trained weights ready for use. These weights will be in the `/runs/detect/train/weights/best.pt` folder of your project. You can upload your model weights to Roboflow Deploy to use your trained weights on our infinitely scalable infrastructure.\n","\n","The `.deploy()` function in the [Roboflow pip package](https://docs.roboflow.com/python) now supports uploading YOLOv8 weights.\n","\n","To upload model weights, add the following code to the “Inference with Custom Model” section in the aforementioned notebook:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6EhBAJ2gCPZh","outputId":"259decf5-1c4e-4011-a208-a2498acc30ca"},"outputs":[],"source":["project.version(dataset.version).deploy(model_type=\"yolov8\", model_path=f\"{HOME}/runs/detect/train/\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q5kOhjkmcV1l"},"outputs":[],"source":["#While your deployment is processing, checkout the deployment docs to take your model to most destinations https://docs.roboflow.com/inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I4bpUIibcV1l"},"outputs":[],"source":["#Run inference on your model on a persistant, auto-scaling, cloud API\n","\n","#load model\n","model = project.version(dataset.version).model\n","\n","#choose random test set image\n","import os, random\n","test_set_loc = dataset.location + \"/test/images/\"\n","random_test_image = random.choice(os.listdir(test_set_loc))\n","print(\"running inference on \" + random_test_image)\n","\n","pred = model.predict(test_set_loc + random_test_image, confidence=40, overlap=30).json()\n","pred"]},{"cell_type":"markdown","metadata":{"id":"9Z7GZvj1p7oL"},"source":["# Deploy Your Model to the Edge\n","\n","In addition to using the Roboflow hosted API for deployment, you can use [Roboflow Inference](https://inference.roboflow.com), an open source inference solution that has powered millions of API calls in production environments. Inference works with CPU and GPU, giving you immediate access to a range of devices, from the NVIDIA Jetson to TRT-compatible devices to ARM CPU devices.\n","\n","With Roboflow Inference, you can self-host and deploy your model on-device. You can deploy applications using the [Inference Docker containers](https://inference.roboflow.com/quickstart/docker/) or the pip package.\n","\n","For example, to install Inference on a device with an NVIDIA GPU, we can use:\n","\n","```\n","docker pull roboflow/roboflow-inference-server-gpu\n","```\n","\n","Then we can run inference via HTTP:\n","\n","```python\n","import requests\n","\n","workspace_id = \"\"\n","model_id = \"\"\n","image_url = \"\"\n","confidence = 0.75\n","api_key = \"\"\n","\n","infer_payload = {\n","    \"image\": {\n","        \"type\": \"url\",\n","        \"value\": image_url,\n","    },\n","    \"confidence\": confidence,\n","    \"iou_threshold\": iou_thresh,\n","    \"api_key\": api_key,\n","}\n","res = requests.post(\n","    f\"http://localhost:9001/{workspace_id}/{model_id}\",\n","    json=infer_object_detection_payload,\n",")\n","\n","predictions = res.json()\n","```\n","\n","Above, set your Roboflow workspace ID, model ID, and API key.\n","\n","- [Find your workspace and model ID](https://docs.roboflow.com/api-reference/workspace-and-project-ids?ref=blog.roboflow.com)\n","- [Find your API key](https://docs.roboflow.com/api-reference/authentication?ref=blog.roboflow.com#retrieve-an-api-key)\n","\n","Also, set the URL of an image on which you want to run inference. This can be a local file.\n","\n","_To use your YOLOv5 model commercially with Inference, you will need a Roboflow Enterprise license, through which you gain a pass-through license for using YOLOv5. An enterprise license also grants you access to features like advanced device management, multi-model containers, auto-batch inference, and more._"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cnfuD7_Mp7oM"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ovQgOj_xSNDg"},"source":["## 🏆 Congratulations\n","\n","### Learning Resources\n","\n","Roboflow has produced many resources that you may find interesting as you advance your knowledge of computer vision:\n","\n","- [Roboflow Notebooks](https://github.com/roboflow/notebooks): A repository of over 20 notebooks that walk through how to train custom models with a range of model types, from YOLOv7 to SegFormer.\n","- [Roboflow YouTube](https://www.youtube.com/c/Roboflow): Our library of videos featuring deep dives into the latest in computer vision, detailed tutorials that accompany our notebooks, and more.\n","- [Roboflow Discuss](https://discuss.roboflow.com/): Have a question about how to do something on Roboflow? Ask your question on our discussion forum.\n","- [Roboflow Models](https://roboflow.com): Learn about state-of-the-art models and their performance. Find links and tutorials to guide your learning.\n","\n","### Convert data formats\n","\n","Roboflow provides free utilities to convert data between dozens of popular computer vision formats. Check out [Roboflow Formats](https://roboflow.com/formats) to find tutorials on how to convert data between formats in a few clicks.\n","\n","### Connect computer vision to your project logic\n","\n","[Roboflow Templates](https://roboflow.com/templates) is a public gallery of code snippets that you can use to connect computer vision to your project logic. Code snippets range from sending emails after inference to measuring object distance between detections."]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/roboflow-ai/notebooks/blob/main/notebooks/train-yolov8-object-detection-on-custom-dataset.ipynb","timestamp":1697060086168}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
